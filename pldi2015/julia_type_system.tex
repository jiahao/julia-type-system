\section{The Julia Type System}

\begin{quote}
  \textit{Ceci n'est pas une type} \\
  (With apologies to H. Magritte)
\end{quote}

\subsection{Basics}
\TODO{This is where we write one of those trees.}

\paragraph{What is a type?}

The defining feature of dynamic typing is that all values, semantically at least, have
two parts: a \emph{tag} and some \emph{data}. The tag classifies the value according to
some ontology defined by the programming language, and the data is a block of memory
whose format is set by the programming language, possibly in a way that depends on the
tag.

Colloquially tags are typically called ``types'' by programmers, as the distinction
is not important in most uses of dynamic typing. In type theory each tag corresponds
one-to-one to a type encoding the proposition that some term evaluates to a value
with that tag. However dynamically-typed languages usually do not require that such
a type system be used. Statically determining all tags is generally not possible.
Furthermore, it would be perfectly reasonable to impose a static type system that
was not concerned with tags at all, but rather with other program properties
(e.g. checking for possible uses of null references). Tags are a mechanism, and as
such neither require nor preclude any particular formalism.

Tags are valuable because they have a constrained structure. While the data
part of a value may vary arbitrarily at run time, tags are drawn from a limited,
well-understood family. This provides for self-describing data: it becomes possible
to write a program that accepts an \emph{arbitrary} value, discovers its structure,
and operates on it, by examining its tag.

The potential of tags is to provide a common descriptive language shared by all users
of a language, as well as the compiler. The cost of tags is overhead. The addition of
a tag may double, or more, the memory footprint of a data item. Partly for this reason,
most dynamically typed languages try to simplify and minimize their tag systems.
(Laurence Tratt also points out that tags tend to resemble the types used in static
languages, likely as a result of cultural expectations \cite{}.) Taken to an extreme,
as in Scheme, the set of possible tags might be finite and small, allowing tags to be
overlaid with pointer bits in many implementations.

Julia tries to reach the other extreme, providing for tags with nested structure, and
possibly containing arbitrary values.

- describing when code is applicable (dispatch)
- describing what to specialize on
- describing memory layout
- describing what, if anything, is statically known about a potential value

\paragraph{Dataflow analysis}

% TODO bit of background

A somewhat unusual feature of julia is that we consider dataflow type inference a
key part of the language. Strictly speaking, this is an optional, external program
analysis that might be used for various purposes, chief among them implementing
an optimizing compiler. However, it is highly important to programmers since it
largely defines not the semantics, but the performance model of the language.

We feel that dataflow analysis, especially of forward flow, captures a piece of
the human intuition of how programs work: values start at the top and move through
the program step by step. For example, compilers are much more user-friendly
when they elide a possibly-uninitialized variable warning in

int a;
if (cond)
    a = 1;
else
    a = 2;
f(a);

The programmer knows that \code{a} is always initialized before use.

\paragraph{Subtyping relations and the type lattice}

\paragraph{\code{typeof}}

You can define \code{typeof} axiomatically as having the following behavior on a \code{value=(bits, tag)} pair:

\begin{minted}[frame=lines,framesep=2mm]{julia}
typeof(bits, tag) = (tag, DataType) #Returns a value
\end{minted}

\code{typeof} has a fixed point, namely \code{(DataType, DataType)}. This is also true in other dynamic languages, e.g. Python (CPython). In other languages like Haskell, \code{typeof(DataType) = Kind}, etc. Static languages can just truncate the tower of metatypes and also refuse to type-check code that reasons about types and kinds too far up the hierarchy. In fact, early versions of Haskell did not allow for programs to reason about kinds at the data type level due to the lack of kind polymorphism~\cite{haskellkindtypes}.

\TODO{There is a subtlety about typeof's behavior. typeof is a projection; typeof(not-a-type) produces a DataType, which projects non-type values onto types. It also has the effect of lifting non-type values onto a type lattice; the latter is defined only for values that are DataTypes.}

\paragraph{Widening}

\TODO{Formal proof of correctness?}

\subsection{Dispatch}

\paragraph{method sorting for specificity}

\TODO{The main novelty and challenge is explaining type parameters and typevars. Currently typevars are not first-class objects in Julia; you can't pass them to a function. Expressions of the form \code{T<:SomeType} don't have an independent existence outside a function signature that also contains the \code{\{T...\}} construction.}

\subsection{Type Inference}

\subsection{Type promotion}

\subsection{Example: modular integer arithmetic with \code{lcm}}

Here's an example of a type parameter computed with the \code{lcm} function:

\begin{minted}[frame=lines,fontsize=\footnotesize,
               framesep=2mm]{julia}
import Base: convert, promote_rule, show, showcompact

immutable ModInt{n} <: Integer
    k::Int
    ModInt(k) = new(mod(k,n))
end

-{n}(a::ModInt{n}) = ModInt{n}(-a.k)
+{n}(a::ModInt{n}, b::ModInt{n}) = ModInt{n}(a.k+b.k)
-{n}(a::ModInt{n}, b::ModInt{n}) = ModInt{n}(a.k-b.k)
*{n}(a::ModInt{n}, b::ModInt{n}) = ModInt{n}(a.k*b.k)

convert{n}(::Type{ModInt{n}}, k::Int) = ModInt{n}(k)
convert{n}(::Type{ModInt{n}}, k::ModInt) = ModInt{n}(k.k)
promote_rule{n}(::Type{ModInt{n}}, ::Type{Int}) = ModInt{n}
promote_rule{m,n}(::Type{ModInt{m}}, ::Type{ModInt{n}}) =
    ModInt{lcm(m,n)}

show{n}(io::IO, k::ModInt{n}) = print(io, "$(k.k) mod $n")
showcompact(io::IO, k::ModInt) = print(io, k.k)

julia> a = ModInt{12}(18278176231)
7 mod 12

julia> b = ModInt{15}(2837628736423)
13 mod 15

julia> a + b
20 mod 60
\end{minted}

The type of the result \code{a + b} depends on the types of \code{a} and \code{b} via \code{lcm}.
