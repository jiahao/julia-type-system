\section{The Julia Type System}

\begin{quote}
  \textit{Ceci n'est pas une type} \\
  (With apologies to H. Magritte)
\end{quote}

We now define the types in Julia. We have designed the type system to be as permissive as possible to programmers while still providing enough information to statically resolve a significant portion of dispatches. The main contribution of the type system design is that types are values that the programmer can write programs to compute. The challenge in designing such a type system are in specifying how tags can be computed and how the subtyping relationships work. [Question: is this type system based on/similar to any other type system?]
Motivating reason: having types as values allows you to have fewer components to the language design. Lets you write array parametric on a type without explicitly declaring the type parameter.
Main challenges:
- Types/tags exist to describe things in a standard way. Challenge to think about what needs to be described. Canonical example for long time was arrays with different element types.
[What were the main difficulties in designing the type system?]
[What about promoters? Do type promotions show up in other languages?]
Type promotions are written as user-level code to compute new types.

In Figure [FIGURE REF] we show Julia’s types. A type can be an abstract [what the heck is an abstract], a data constructor [is this a record?], a tuple, a quantification over a set of types, a union, or a singleton type. In the code, singletons are used for computations on types themselves, such as type promotions. For example, given two types, can ask what the promoted type is. So far haven’t had singleton types for general values. (Sorting algorithms example: used more for dispatch as shorthand for type with no parameters.) Will use this more because generating specialized code is big for scientific computing, but need to figure out what to specialize on and how to tell system what to specialize on. State of the art is to have ad hoc systems.

An abstract type declares a type without a representation. It takes the name of a type, parameters [what do the parameters do?], and the name of the super type. Data type declarations additionally provide a representation. [TODO: Talk about the representation.]
Abstract type and data type declarations are invariant and nominative.

Tuples are covariant.

ForAll types quantify over all types between a lower bound and upper bound. Have lower bound and upper bound because of containers that can be read and written. People mostly only use the upper bounds. No function types, so no contravariance, so lower bounds don’t get used much. In theory, can still use them for functions that mutate things.

[How does type promotion fit into all this?]

\begin{minted}[frame=lines,framesep=2mm]{julia}
Type ::= Abstract | Data | Tuple | ForAll | Union | Singleton
Abstract ::= Name (P) Super }
Data ::= Name (P) Super Repr } invariant, nominative
TODO: What is repr?
Tuple ::= (T1, T2, …) | (T1, T2, …, Tn, …) } covariant
ForAll ::= $\forall$ (lb <: T <: ub) . Type
Union ::= U (T1, T2, …)
Singleton ::= Lift Value
TypeVar ::= lb <: Name <: ub
top ::= Any
--
Tag ::= Data | Tuple
\end{minted}

\subsection{Basics}
\TODO{This is where we write one of those trees.}

Can write procedures to subtype.

Jeff is pretty sure subtyping is decidable and well-defined
Join is union of any two types; meet is less well-defined in this lattice

What are types in Julia?
Dynamically typed.
What is inheritance like?
How does Julia avoid problems that OO languages tend to have with dispatch? (I’m not actually sure what they are.)
Is there multiple inheritance?
No, but it’s been discussed (https://github.com/JuliaLang/julia/issues/5)
Is there multiple subtyping?
No, each type has only one supertype
We should also describe the dispatch mechanism.
Method tables are a sorted list of these types.
Implemented as \code{jl\_methtable\_t}

\paragraph{What is a type?}

The defining feature of dynamic typing is that all values, semantically at least, have
two parts: a \emph{tag} and some \emph{data}. The tag classifies the value according to
some ontology defined by the programming language, and the data is a block of memory
whose format is set by the programming language, possibly in a way that depends on the
tag.

Colloquially tags are typically called ``types'' by programmers, as the distinction
is not important in most uses of dynamic typing. In type theory each tag corresponds
one-to-one to a type encoding the proposition that some term evaluates to a value
with that tag. However dynamically-typed languages usually do not require that such
a type system be used. Statically determining all tags is generally not possible.
Furthermore, it would be perfectly reasonable to impose a static type system that
was not concerned with tags at all, but rather with other program properties
(e.g. checking for possible uses of null references). Tags are a mechanism, and as
such neither require nor preclude any particular formalism.

Tags are valuable because they have a constrained structure. While the data
part of a value may vary arbitrarily at run time, tags are drawn from a limited,
well-understood family. This provides for self-describing data: it becomes possible
to write a program that accepts an \emph{arbitrary} value, discovers its structure,
and operates on it, by examining its tag.

The potential of tags is to provide a common descriptive language shared by all users
of a language, as well as the compiler. The cost of tags is overhead. The addition of
a tag may double, or more, the memory footprint of a data item. Partly for this reason,
most dynamically typed languages try to simplify and minimize their tag systems.
(Laurence Tratt also points out that tags tend to resemble the types used in static
languages, likely as a result of cultural expectations \cite{}.) Taken to an extreme,
as in Scheme, the set of possible tags might be finite and small, allowing tags to be
overlaid with pointer bits in many implementations.

Julia tries to reach the other extreme, providing for tags with nested structure, and
possibly containing arbitrary values.

- describing when code is applicable (dispatch)
- describing what to specialize on
- describing memory layout
- describing what, if anything, is statically known about a potential value

\paragraph{Dataflow analysis}

What is the goal of the dataflow analysis? Primarily for static type inference. Eliminate runtime checks. Lattice-based. Kaplan-Ullman.
Problem is finding the tightest possible set of allowable types.
There are tweaks to the standard algorithm. One big thing is that dataflow analysis only goes in forward direction.
Kaplan-Ullman also doesn’t treat parametric types
Julia also has a widening step.
Relies on types having only one supertype.
Diagonal dispatch: can constrain arguments to same type.

\TODO{What are the challenges?}

\TODO{What is the complexity?}

\TODO{What is the best way to express this?}

\TODO{bit of background}

\paragraph{Type inference is a key part of the language}
A somewhat unusual feature of julia is that we consider dataflow type inference a
key part of the language. Strictly speaking, this is an optional, external program
analysis that might be used for various purposes, chief among them implementing
an optimizing compiler. However, it is highly important to programmers since it
largely defines not the semantics, but the performance model of the language.

We feel that dataflow analysis, especially of forward flow, captures a piece of
the human intuition of how programs work: values start at the top and move through
the program step by step. For example, compilers are much more user-friendly
when they elide a possibly-uninitialized variable warning in

\begin{minted}[frame=lines,framesep=2mm]{julia}
int a;
if (cond)
    a = 1;
else
    a = 2;
f(a);
\end{minted}

The programmer knows that \code{a} is always initialized before use.

\paragraph{Subtyping relations and the type lattice}

\paragraph{\code{typeof}}

You can define \code{typeof} axiomatically as having the following behavior on a \code{value=(bits, tag)} pair:

\begin{minted}[frame=lines,framesep=2mm]{julia}
typeof(bits, tag) = (tag, DataType) #Returns a value
\end{minted}

\code{typeof} has a fixed point, namely \code{(DataType, DataType)}. This is also true in other dynamic languages, e.g. Python (CPython). In other languages like Haskell, \code{typeof(DataType) = Kind}, etc. Static languages can just truncate the tower of metatypes and also refuse to type-check code that reasons about types and kinds too far up the hierarchy. In fact, early versions of Haskell did not allow for programs to reason about kinds at the data type level due to the lack of kind polymorphism~\cite{haskellkindtypes}.

\TODO{There is a subtlety about typeof's behavior. typeof is a projection; typeof(not-a-type) produces a DataType, which projects non-type values onto types. It also has the effect of lifting non-type values onto a type lattice; the latter is defined only for values that are DataTypes.}

\paragraph{Widening}

\TODO{Formal proof of correctness?}

\subsection{Dispatch}

\paragraph{method sorting for specificity}

\TODO{The main novelty and challenge is explaining type parameters and typevars. Currently typevars are not first-class objects in Julia; you can't pass them to a function. Expressions of the form \code{T<:SomeType} don't have an independent existence outside a function signature that also contains the \code{\{T...\}} construction.}

\subsection{Type Inference}

\subsection{Type promotion}

\subsection{Example: modular integer arithmetic with \code{lcm}}

Here's an example of a type parameter computed with the \code{lcm} function:

\begin{minted}[frame=lines,fontsize=\footnotesize,
               framesep=2mm]{julia}
import Base: convert, promote_rule, show, showcompact

immutable ModInt{n} <: Integer
    k::Int
    ModInt(k) = new(mod(k,n))
end

-{n}(a::ModInt{n}) = ModInt{n}(-a.k)
+{n}(a::ModInt{n}, b::ModInt{n}) = ModInt{n}(a.k+b.k)
-{n}(a::ModInt{n}, b::ModInt{n}) = ModInt{n}(a.k-b.k)
*{n}(a::ModInt{n}, b::ModInt{n}) = ModInt{n}(a.k*b.k)

convert{n}(::Type{ModInt{n}}, k::Int) = ModInt{n}(k)
convert{n}(::Type{ModInt{n}}, k::ModInt) = ModInt{n}(k.k)
promote_rule{n}(::Type{ModInt{n}}, ::Type{Int}) = ModInt{n}
promote_rule{m,n}(::Type{ModInt{m}}, ::Type{ModInt{n}}) =
    ModInt{lcm(m,n)}

show{n}(io::IO, k::ModInt{n}) = print(io, "$(k.k) mod $n")
showcompact(io::IO, k::ModInt) = print(io, k.k)

julia> a = ModInt{12}(18278176231)
7 mod 12

julia> b = ModInt{15}(2837628736423)
13 mod 15

julia> a + b
20 mod 60
\end{minted}

The type of the result \code{a + b} depends on the types of \code{a} and \code{b} via \code{lcm}.
